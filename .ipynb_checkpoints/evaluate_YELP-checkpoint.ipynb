{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "10   11\n",
      "4   4\n",
      "3   3\n",
      "7   7\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "6   6\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "4   4\n",
      "8   8\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "7   7\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "7   7\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "13   13\n",
      "6   6\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "3   3\n",
      "4   4\n",
      "4   4\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "7   7\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "5   5\n",
      "8   8\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "23   24\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "4   4\n",
      "7   7\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "6   6\n",
      "3   3\n",
      "4   4\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "7   7\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "14   13\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "7   7\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "7   7\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "3   3\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "7   7\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "8   8\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "5   5\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "6   6\n",
      "3   3\n",
      "2   2\n",
      "15   15\n",
      "14   13\n",
      "2   2\n",
      "6   6\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "7   7\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "6   6\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "4   4\n",
      "2   2\n",
      "3   3\n",
      "4   4\n",
      "3   3\n",
      "5   5\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "26   27\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "11   11\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "6   6\n",
      "2   2\n",
      "8   8\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "11   11\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "8   8\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "6   6\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "7   7\n",
      "6   6\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "7   7\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "4   4\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "5   5\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "15   15\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "5   5\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "14   13\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "6   6\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "3   3\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "6   6\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "5   5\n",
      "3   3\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "10   11\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "6   6\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "4   4\n",
      "4   4\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "3   3\n",
      "2   2\n",
      "2   2\n",
      "2   2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from random import shuffle\n",
    "import eval.stats\n",
    "import utils\n",
    "from args import Args\n",
    "import networkx as nx\n",
    "args = Args()\n",
    "pred_dir_input = \"./\"+\"modified_graphs/\" # args.dir_input + \"/graphs/\" \n",
    "test_dir_input = \"./\" + \"graphs/\"\n",
    "model_name = 'GraphRNN_RNN' # self.model_name_all --> evaluation.py\n",
    "pred_dataset_name = 'yelp' # self.dataset_name_all --> evaluation.py \n",
    "test_dataset_name = 'YELP' # self.dataset_name_all --> evaluation.py \n",
    "hidden = 128 # evaluate.py -> evaluation -> evaluation_epoch\n",
    "epoch = 2 # we need the final epoch trained lstm performance on test graph to give the best predict \n",
    "sample_time = 1 # only one, because we use GRAPHRNN_RNN --> evaluate.p -> evaluation -> evaluation_epoch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fname_test = test_dir_input + model_name + '_' + test_dataset_name + '_' + str(args.num_layers) + '_' + str(hidden) + '_test_' + str(0) + '.dat'\n",
    "fname_pred = pred_dir_input + model_name + '_' + pred_dataset_name + '_' + str(args.num_layers) + '_' + str(hidden) + '_pred_' + str(epoch) + '.dat'\n",
    "\n",
    "\n",
    "\n",
    "graph_test = utils.load_graph_list(fname_test,is_real=True)\n",
    "graph_pred = utils.load_graph_list(fname_pred,is_real=False)\n",
    "graph_test_len = len(graph_test)\n",
    "graph_train = graph_test[0:int(0.8 * graph_test_len)] # train\n",
    "graph_validate = graph_test[0:int(0.2 * graph_test_len)] # validate\n",
    "graph_test = graph_test[int(0.8 * graph_test_len):] # test on a hold out test set\n",
    "\n",
    "## CLEAN GRAPH\n",
    "def find_nearest_idx(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "\n",
    "# shuffle(graph_test)\n",
    "# shuffle(graph_pred)\n",
    "\n",
    "# get length\n",
    "real_graph_len = np.array([len(graph_test[i]) for i in range(len(graph_test))])\n",
    "pred_graph_len = np.array([len(graph_pred[i]) for i in range(len(graph_pred))])\n",
    "# print(real_graph_len,len(pred_graph_len))\n",
    "\n",
    "# select pred samples\n",
    "# The number of nodes are sampled from the similar distribution as the training set\n",
    "pred_graph_new = []\n",
    "pred_graph_len_new = []\n",
    "for value in real_graph_len:\n",
    "    pred_idx = find_nearest_idx(pred_graph_len, value)\n",
    "    pred_graph_new.append(graph_pred[pred_idx])\n",
    "    pred_graph_len_new.append(pred_graph_len[pred_idx])\n",
    "\n",
    "graph_pred = pred_graph_new\n",
    "graph_real = graph_test\n",
    "# min_len = min(len(graph_test),len(graph_pred))\n",
    "\n",
    "num_of_matches = 0\n",
    "pred_to_real_dic = {}\n",
    "matches = 0\n",
    "for idx in range(len(graph_pred)):\n",
    "    real_nodes = graph_test[idx].nodes()\n",
    "    pred_nodes = graph_pred[idx].nodes()\n",
    "    print(len(real_nodes),' ',len(pred_nodes))\n",
    "    if len(real_nodes) == len(pred_nodes):\n",
    "        matches += 1\n",
    "print(matches/len(graph_pred))    \n",
    "    \n",
    "# TP = 0\n",
    "# FP = 0\n",
    "# FN = 0\n",
    "\n",
    "    \n",
    "# for item in real_edges:\n",
    "#     if item in pred_edges:\n",
    "#         TP += 1\n",
    "#     if item not in pred_edges:\n",
    "#         FN += 1\n",
    "# for item in pred_edges:\n",
    "#     if item not in real_edges:\n",
    "#         FP += 1\n",
    "# precision = TP/(TP+FP)\n",
    "# recall = TP/(TP+FN)\n",
    "# F1_value = 2*precision*recall/(precision+recall)\n",
    "# print('precision: ',precision,'recall: ',recall, 'F1-value: ',F1_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from utils import *\n",
    "from data import *\n",
    "\n",
    "args = Args()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.cuda)\n",
    "print('CUDA', args.cuda)\n",
    "if args.clean_tensorboard:\n",
    "    if os.path.isdir(\"tensorboard\"):\n",
    "        shutil.rmtree(\"tensorboard\")\n",
    "        \n",
    "# time = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "# configure(\"tensorboard/run\"+time, flush_secs=5)\n",
    "\n",
    "graphs = create_graphs.create(args)\n",
    "# split datasets\n",
    "random.seed(123)\n",
    "shuffle(graphs)\n",
    "graphs_len = len(graphs)\n",
    "graphs_test = graphs[int(0.8 * graphs_len):]\n",
    "graphs_train = graphs[0:int(0.8*graphs_len)]\n",
    "graphs_validate = graphs[0:int(0.2*graphs_len)]\n",
    "\n",
    "\n",
    "args.max_num_node = max([graphs[i].number_of_nodes() for i in range(len(graphs))])\n",
    "max_num_edge = max([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "min_num_edge = min([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "\n",
    "\n",
    "\n",
    "dataset = Graph_sequence_sampler_pytorch(graphs_train,max_prev_node=args.max_prev_node,max_num_node=args.max_num_node)\n",
    "sample_strategy = torch.utils.data.sampler.WeightedRandomSampler([1.0 / len(dataset) for i in range(len(dataset))],\n",
    "                                                                 num_samples=args.batch_size*args.batch_ratio, replacement=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "                                           sampler=sample_strategy)\n",
    "rnn = GRU_plain(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                has_output=True, output_size=args.hidden_size_rnn_output).cuda()\n",
    "output = GRU_plain(input_size=1, embedding_size=args.embedding_size_rnn_output,\n",
    "                   hidden_size=args.hidden_size_rnn_output, num_layers=args.num_layers, has_input=True,\n",
    "                   has_output=True, output_size=1).cuda()\n",
    "epoch = 1\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer_rnn = optim.Adam(list(rnn.parameters()), lr=args.lr)\n",
    "optimizer_output = optim.Adam(list(output.parameters()), lr=args.lr)\n",
    "\n",
    "scheduler_rnn = MultiStepLR(optimizer_rnn, milestones=args.milestones, gamma=args.lr_rate)\n",
    "scheduler_output = MultiStepLR(optimizer_output, milestones=args.milestones, gamma=args.lr_rate)\n",
    "while epoch<=args.epochs:\n",
    "    rnn.train() #sets the model on train mode\n",
    "    output.train()\n",
    "    loss_sum = 0\n",
    "    for batch_idx, data in enumerate(dataset_loader):\n",
    "        rnn.zero_grad()\n",
    "        output.zero_grad()\n",
    "        x_unsorted = data['x'].float()\n",
    "        y_unsorted = data['y'].float()\n",
    "    print(y_unsorted.size(0), ' ',y_unsorted.size(1))\n",
    "    print(x_unsorted.size(1),' ',x_unsorted.size(1))\n",
    "    epoch += 1\n",
    "    if epoch == 2:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.ones(8)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
